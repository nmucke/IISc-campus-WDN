{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/scratch1/ntm/nikolaj_workstation_data/PhD\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import wntr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "\n",
    "from ML_for_WDN.data_utils import clean_dataframes, load_data\n",
    "\n",
    "from ML_for_WDN.models import UnsupervisedLeakDetector\n",
    "\n",
    "# set working directory to root directory\n",
    "%cd ..\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "LATENT_DIM = 8\n",
    "SUPERVISED = False\n",
    "\n",
    "ENCODER_ARGS = {\n",
    "    'hidden_dims': [16, 12, 8],\n",
    "    'latent_dim': LATENT_DIM,\n",
    "}\n",
    "\n",
    "DECODER_ARGS = {\n",
    "    'latent_dim': LATENT_DIM,\n",
    "    'hidden_dims': [8, 12, 16],\n",
    "    'num_pars': 4 if SUPERVISED else None,\n",
    "}\n",
    "\n",
    "\n",
    "DATA_FILES_TRAIN = [\n",
    "    'data/data_no_leak.xlsx',\n",
    "]\n",
    "\n",
    "DATA_FILES_TEST = [\n",
    "    'data/data_leak_1.xlsx',\n",
    "    'data/data_leak_2.xlsx',\n",
    "    'data/data_leak_3.xlsx',\n",
    "]\n",
    "\n",
    "columns_to_use = [\n",
    "    'FM01_flow', 'FM02_head', 'FM03_flow', 'FM05_flow', 'FM06_flow', 'FM08_flow', 'FM09_flow', 'FM11_flow', 'FM13_flow',\n",
    "    'FM01_head', 'FM02_flow', 'FM03_head', 'FM05_head', 'FM06_head', 'FM08_head', 'FM09_head', 'FM11_head', 'FM13_head',\n",
    "]\n",
    "\n",
    "dataframes = []\n",
    "for data_file in DATA_FILES_TRAIN:\n",
    "    df = load_data(data_file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "dataframes = clean_dataframes(\n",
    "    dataframes,\n",
    "    columns_to_use=columns_to_use,\n",
    ")\n",
    "train_data = dataframes[0]\n",
    "\n",
    "test_data = train_data.iloc[-5000:, :]\n",
    "train_data = train_data.iloc[:-5000, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Training stage 1 ##########\n",
      "\n",
      "\n",
      "Training autoencoder without leak data\n",
      "\n",
      "\n",
      "Autoencoder architecture:\n",
      "- Latent dimension: 8\n",
      "- Encoder hidden dimensions: [16, 12, 8]\n",
      "- Decoder hidden dimensions: [8, 12, 16]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7872 | Latent: 2.1884:  12%|█▏        | 116/1000 [00:17<02:12,  6.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     16\u001b[0m anomaly_detection_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m UnsupervisedLeakDetector(\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mNN_args,\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNN_train_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNN_train_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43manomaly_detection_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manomaly_detection_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m DATA_FILES_TEST:\n",
      "File \u001b[0;32m/export/scratch1/ntm/nikolaj_workstation_data/PhD/ML-for-WDN/src/ML_for_WDN/models.py:52\u001b[0m, in \u001b[0;36mUnsupervisedLeakDetector.fit\u001b[0;34m(self, data, NN_train_args, anomaly_detection_args, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Decoder hidden dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrain_WAE\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNN_train_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoencoder training complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/export/scratch1/ntm/nikolaj_workstation_data/PhD/ML-for-WDN/src/ML_for_WDN/NN_utils.py:71\u001b[0m, in \u001b[0;36mtrain_WAE\u001b[0;34m(data, model, train_args, device, supervised_pars)\u001b[0m\n\u001b[1;32m     68\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(latent)\n\u001b[1;32m     69\u001b[0m latent_loss \u001b[38;5;241m=\u001b[39m MMD(latent, z, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 71\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, batch_data) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\u001b[38;5;241m*\u001b[39mlatent_loss\n\u001b[1;32m     74\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/export/scratch1/ntm/nikolaj_workstation_data/PhD/ML-for-WDN/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/export/scratch1/ntm/nikolaj_workstation_data/PhD/ML-for-WDN/src/ML_for_WDN/WAE.py:148\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, pars)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_layer, batch_norm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norms):\n\u001b[1;32m    147\u001b[0m     x \u001b[38;5;241m=\u001b[39m hidden_layer(x)\n\u001b[0;32m--> 148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m(x)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m#x = batch_norm(x)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n",
      "File \u001b[0;32m/export/scratch1/ntm/nikolaj_workstation_data/PhD/ML-for-WDN/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_backward_pre_hooks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m-> 1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1603\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessor = StandardScaler().fit(train_data.values)\n",
    "train_data = preprocessor.transform(train_data.values)\n",
    "\n",
    "NN_args = {\n",
    "    'encoder_args': ENCODER_ARGS,\n",
    "    'decoder_args': DECODER_ARGS,\n",
    "}\n",
    "NN_train_args = {\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 512,\n",
    "    'lr': 5e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'loss_fn': nn.MSELoss(),\n",
    "    'supervised_pars': None,\n",
    "}\n",
    "anomaly_detection_args = {\n",
    "}\n",
    "model = UnsupervisedLeakDetector(\n",
    "    **NN_args,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    data=train_data,\n",
    "    NN_train_args=NN_train_args,\n",
    "    anomaly_detection_args=anomaly_detection_args,\n",
    "    device='cpu',\n",
    ")\n",
    "\n",
    "dataframes = []\n",
    "for data_file in DATA_FILES_TEST:\n",
    "    df = load_data(data_file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "dataframes = clean_dataframes(\n",
    "    dataframes,\n",
    "    columns_to_use=columns_to_use,\n",
    ")\n",
    "dataframes = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "test_data = pd.concat([test_data, dataframes], ignore_index=True)\n",
    "test_data = preprocessor.transform(test_data.values)\n",
    "\n",
    "targets = np.zeros((test_data.shape[0]))\n",
    "targets[0:5000] = 1\n",
    "targets[5000:] = -1\n",
    "\n",
    "preds = model.predict(\n",
    "    X=test_data,\n",
    ")\n",
    "cm = confusion_matrix(targets, preds)\n",
    "print(f'Accuracy: {accuracy_score(targets, preds):0.3f}')\n",
    "print(f'Recall: {cm[1,1]/(cm[1,1]+cm[1,0])}')\n",
    "print(f'Precision: {cm[1,1]/(cm[1,1]+cm[0,1])}')\n",
    "    \n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=['leak', 'No Leak'],\n",
    ")\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
